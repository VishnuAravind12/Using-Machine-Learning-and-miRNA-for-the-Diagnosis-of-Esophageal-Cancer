{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train/test dataset and replace 'Selected'/'Random' in 'Name' with 1/0\n",
    "dataframe = pd.read_csv(r'Post_WEKA\\Output Data.csv')\n",
    "dataframe['Name'] = dataframe['Name'].replace({'Selected': 1, 'Random': 0})\n",
    "\n",
    "# Split dataset into features (X) and target (Y)\n",
    "dataset = dataframe.values\n",
    "X = dataset[:, 0:-1].astype(float)\n",
    "Y = dataset[:, -1]\n",
    "\n",
    "# Split data into training and test sets (0.8 for train, 0.2 for test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    # Define model input with shape 476\n",
    "    inputs = keras.Input(shape=(476,))\n",
    "    x = inputs\n",
    "\n",
    "    # Dynamically add dense layers based on hyperparameter 'mlplayers'\n",
    "    for i in range(hp.Int(\"mlplayers\", 2, 8)):\n",
    "        x = keras.layers.Dense(\n",
    "            units=hp.Int(\"units\", 32, 512, step=32), activation=\"relu\"\n",
    "        )(x)\n",
    "\n",
    "    # Dropout layer to reduce overfitting\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Output layer with sigmoid activation for binary classification\n",
    "    outputs = keras.layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Hyperparameter tuning for learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    # Compile model with Adam optimizer\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    overwrite=True,\n",
    "    factor=3,\n",
    "    objective=\"val_accuracy\",\n",
    "    directory=\"/tmp/tb\",\n",
    ")\n",
    "\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor='loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    callbacks=[stop_early, keras.callbacks.TensorBoard(\"/tmp/tb_logs\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the best hyperparameters from the tuner\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Build the model using the best hyperparameters from tuning\n",
    "model = model_builder(best_hp)\n",
    "\n",
    "# Compile the model with Adam optimizer and binary crossentropy loss\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=best_hp.get('learning_rate')),\n",
    "              loss=\"binary_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model on the training dataset\n",
    "history = model.fit(x_train, y_train, epochs=6)\n",
    "\n",
    "# Evaluate the model's performance on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "# Print the test loss and accuracy\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Alternative Test Data (from the external study) into numpy arrays for model testing\n",
    "\n",
    "dataframe = pd.read_csv(r'Alternative_Test_Data\\Alt_Test_Data.csv')\n",
    "\n",
    "selected_rows = [1, 2, 3, 5, 6, 8, 11, 12, 15, 17] # These are the rows that hold the positive group miRNA (the rest hold control miRNA)\n",
    "\n",
    "x_test_alt = dataframe.iloc[selected_rows, 1:-1].values\n",
    "y_test_alt = np.ones(10)\n",
    "\n",
    "# Negative class is represented by 0\n",
    "negative_class_mask = y_test == 0\n",
    "\n",
    "# Get the negative class records\n",
    "x_test_negative = x_test[negative_class_mask]\n",
    "y_test_negative = y_test[negative_class_mask]\n",
    "\n",
    "# Concatenate the negative class records with the alternative test set\n",
    "x_test_combined = np.concatenate((x_test_alt, x_test_negative[0:10]), axis=0)\n",
    "y_test_combined = np.concatenate((y_test_alt, y_test_negative[0:10]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 0.6220 - accuracy: 0.4951\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.9216\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.9412\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1587 - accuracy: 0.9559\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9265\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.9559\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.9608\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1072 - accuracy: 0.9657\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9657\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 0.9657\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.9657\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9657\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 0.9559\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9608\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9657\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4749 - accuracy: 0.9000\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5833\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.9069\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9265\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.9265\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9559\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9510\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1188 - accuracy: 0.9510\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1046 - accuracy: 0.9657\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9608\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.9657\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9657\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9706\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9706\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9706\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9706\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6137 - accuracy: 0.8500\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 0.6498 - accuracy: 0.5588\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8873\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.9216\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9510\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1176 - accuracy: 0.9510\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9608\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1070 - accuracy: 0.9608\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9608\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0890 - accuracy: 0.9657\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9608\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9706\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9706\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9706\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9706\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9755\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4283 - accuracy: 0.9000\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 0.5933 - accuracy: 0.6520\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.9216\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2184 - accuracy: 0.9216\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1685 - accuracy: 0.9363\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9559\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.9608\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.9657\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9657\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9657\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9657\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9657\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.9657\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9657\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.9706\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.9657\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6991 - accuracy: 0.8500\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 0.6578 - accuracy: 0.6471\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.9167\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9314\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9559\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 0.9412\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9510\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9559\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9608\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9608\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0888 - accuracy: 0.9657\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0864 - accuracy: 0.9657\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9755\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9608\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9755\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.9706\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4992 - accuracy: 0.9000\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 0.6161 - accuracy: 0.6471\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.9118\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1676 - accuracy: 0.9461\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.9608\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9559\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1115 - accuracy: 0.9559\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9608\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.9608\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.9706\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9657\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.9706\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9755\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9755\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9755\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9755\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6256 - accuracy: 0.8500\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 0.6599 - accuracy: 0.6814\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.9069\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9216\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9510\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9510\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 0.9608\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.9657\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.9657\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.9657\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9608\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9559\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.9608\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.9706\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0799 - accuracy: 0.9706\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9706\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4127 - accuracy: 0.9000\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 0.6758 - accuracy: 0.5441\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.9167\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.9314\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9412\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9412\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1338 - accuracy: 0.9510\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9608\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.9608\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9608\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.9657\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0899 - accuracy: 0.9657\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9608\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 0.9657\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9657\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9706\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5489 - accuracy: 0.9500\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 0.6361 - accuracy: 0.6961\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.9069\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9069\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9265\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9461\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9559\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 0.9657\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9608\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.9657\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0835 - accuracy: 0.9657\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9657\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.9657\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.9657\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9657\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0884 - accuracy: 0.9608\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.4815 - accuracy: 0.9000\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 0.6638 - accuracy: 0.5931\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8137\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9167\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1695 - accuracy: 0.9461\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9706\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.9657\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9657\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9657\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9706\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.9657\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9559\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9608\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9755\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9706\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9755\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4745 - accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import mean\n",
    "\n",
    "histories = []\n",
    "test_accuracies = []\n",
    "test_losses = []\n",
    "trials = 10\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"/tmp/tb_logs\")\n",
    "auroc_scores = []\n",
    "mcc_scores = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "\n",
    "# Iterate over the number of trials to train and evaluate the model\n",
    "for trial in range(trials):\n",
    "    # Build the model with the best hyperparameters found by the tuner\n",
    "    model = model_builder(best_hp)\n",
    "    # Compile the model with Adam optimizer and binary crossentropy loss\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=best_hp.get('learning_rate')),\n",
    "              loss=\"binary_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "    # Train the model on the training data\n",
    "    history = model.fit(x_train, y_train, epochs=15, callbacks=[tensorboard_callback])\n",
    "    histories.append(history)\n",
    "    # Record the accuracy for each trial\n",
    "    trial_accuracy = history.history['accuracy']\n",
    "    \n",
    "    # Combine accuracies over trials\n",
    "    if trial == 0:\n",
    "        total_accuracies = trial_accuracy\n",
    "    else:\n",
    "        total_accuracies = np.vstack((total_accuracies, trial_accuracy))\n",
    "    \n",
    "    # Predict probabilities on the test set and calculate ROC AUC score\n",
    "    y_pred_proba = model.predict(x_test_combined)\n",
    "    roc_auc = roc_auc_score(y_test_combined, y_pred_proba)\n",
    "    auroc_scores.append(roc_auc)\n",
    "\n",
    "    # Convert probabilities to binary predictions and calculate confusion matrix\n",
    "    y_pred_int = (y_pred_proba > 0.5).astype(int)\n",
    "    confusion_matrix_trial = confusion_matrix(y_test_combined, y_pred_int)\n",
    "    confusion_matrices.append(confusion_matrix_trial)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(x_test_combined, y_test_combined)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Calculate F1 score and Matthews correlation coefficient\n",
    "    f1 = f1_score(y_test_combined, y_pred_int)\n",
    "    f1_scores.append(f1)\n",
    "    mcc = matthews_corrcoef(y_test_combined, y_pred_int)\n",
    "    mcc_scores.append(mcc)\n",
    "\n",
    "# Calculate the average accuracy across all trials\n",
    "average_accuracy = np.mean(total_accuracies, axis=0)\n",
    "\n",
    "# Append average values of the performance metrics\n",
    "test_accuracies.append(mean(test_accuracies))\n",
    "test_losses.append(mean(test_losses))\n",
    "auroc_scores.append(mean(auroc_scores))\n",
    "mcc_scores.append(mean(mcc_scores))\n",
    "f1_scores.append(mean(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the Confusion Matrices\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "for i, cm in enumerate(confusion_matrices):\n",
    "    plt.figure()\n",
    "    class_labels = ['Control', 'Associated']\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(f\"Confusion Matrix - Trial 2\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_labels))\n",
    "    plt.xticks(tick_marks, class_labels)\n",
    "    plt.yticks(tick_marks, class_labels)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
